{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "in_dir = \"/home/ivm/valid/data/processed_data/step3/\"\n",
    "in_file_date = \"2024-10-18\"\n",
    "# FINNGENID, EVENT_AGE, DATE, VALUE, ABNORM (FinnGen), ABNORM_CUSTOM (Reference ranges), EDGE (helper 1: last measurement, 0: first measurement, 2: second to last measurement)\n",
    "data = pd.read_csv(in_dir + \"krea_\" + in_file_date + \".csv\")\n",
    "# FINNGENID, SEX, + other metadata\n",
    "metadata = pd.read_csv(in_dir + \"krea_\" + in_file_date + \"_meta.csv\")\n",
    "data.DATE = pd.to_datetime(data.DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining quantiles\n",
    "steps = 0.1 # size of quantile steps\n",
    "quants = np.append(np.quantile(data.VALUE, np.arange(0, 1, steps), method=\"higher\"), data.VALUE.max())\n",
    "# Adding column with cut data\n",
    "data[\"QUANT\"] = pd.cut(data.VALUE, quants, include_lowest=True)\n",
    "# Mapping quantiles to tokens\n",
    "quant_df = pd.DataFrame({\"INTERVAL\": data.QUANT.cat.categories}).reset_index(drop=False)\n",
    "quant_df.index = quant_df.index+3 # currently 0-x now 2-x+2 with 1-2 sex tokens\n",
    "quant_map = dict(zip(quant_df.INTERVAL, quant_df.index))\n",
    "# Mapping quantiles to tokens in data\n",
    "data.loc[:,\"EVENT\"] = data.QUANT.map(quant_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex token preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing sex token data\n",
    "static_rows = metadata[[\"FINNGENID\", \"SEX\"]]\n",
    "static_rows[\"SEX\"].values[:] = static_rows[\"SEX\"].map({\"female\": 1, \"male\": 2})\n",
    "static_rows[\"EVENT_AGE\"] = 0 # Sex tokens at time 0\n",
    "static_rows = static_rows.rename({\"SEX\": \"EVENT\"}, axis=1)  \n",
    "\n",
    "# Adding sex tokens to data\n",
    "data = data[[\"FINNGENID\", \"EVENT\", \"EVENT_AGE\"]]\n",
    "data = pd.concat([data, static_rows], ignore_index=True)\n",
    "data = data.sort_values(by=[\"FINNGENID\", \"EVENT_AGE\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_map = dict([(y, x+1) for x,y in enumerate(data.FINNGENID.unique())])\n",
    "data[\"FINNGENID\"] = data.FINNGENID.map(fg_map)\n",
    "data[\"EVENT_AGE\"] = data.EVENT_AGE*365.25 # Converting ages to days\n",
    "data = data[[\"FINNGENID\", \"EVENT_AGE\", \"EVENT\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set size of validation set\n",
    "val_size = 0.1\n",
    "\n",
    "n_indvs = len(fg_map)\n",
    "\n",
    "np.random.seed(2813)\n",
    "indv_idxs = np.random.permutation(n_indvs)\n",
    "n_valid = int(n_indvs*val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/home/ivm/valid/data/processed_data/delphi/krea/2024-10-30/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.loc[data.FINNGENID.isin(indv_idxs[n_valid:])]\n",
    "val_data = data.loc[data.FINNGENID.isin(indv_idxs[:n_valid])]\n",
    "\n",
    "train_memmap = np.memmap(out_dir + \"train.bin\", dtype=\"uint32\", mode=\"w+\", shape=train_data.shape)\n",
    "train_memmap[:] = train_data[:]\n",
    "train_memmap.flush()\n",
    "\n",
    "val_memmap = np.memmap(out_dir + \"val.bin\", dtype=\"uint32\", mode=\"w+\", shape=val_data.shape)\n",
    "val_memmap[:] = val_data[:]\n",
    "val_memmap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(quant_map.values())\n",
    "meta = {\n",
    "    \"vocab_size\": vocab_size+2, ### I have no idea why this has to be +2 but otherwise code fails\n",
    "    \"itos\": {i:i for i in range(vocab_size)}, # not using right now\n",
    "    \"stoi\": {i:i for i in range(vocab_size)} # not really using right now ?\n",
    "}\n",
    "print(meta)\n",
    "with open(out_dir + \"krea_meta.pkl\", \"wb\") as fout: pickle.dump(meta, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir + \"krea_labels.txt\", \"w\") as fout:\n",
    "    for key, value in quant_map.items():\n",
    "        fout.write(\"{},{},{}\\n\".format(key.left, key.right, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir + \"fids.txt\", \"w\") as fout:\n",
    "    for key, value in fg_map.items():\n",
    "        group = 0 # training\n",
    "        if value in indv_idxs[:n_valid]: group = 1 # validation\n",
    "        fout.write(\"{},{},{}\\n\".format(key, value, group))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
